{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_fc_data_file(fc_data_file):\n",
    "    ''' Read an existing functional connectivity data file that also contains labels and demongraphics,\n",
    "    or create it if it doesn't exist. Returns the data file.\n",
    "    Args:\n",
    "        fc_data_file (str): The complete path to the fc data file  \n",
    "    '''\n",
    "    import pandas as pd\n",
    "    if not os.path.exists(fc_data_file):\n",
    "        import create_fc_fisher_z_csv_file as makedata\n",
    "        subjDF = makedata.read_data()\n",
    "        fcData = makedata.read_fc_data(subjDF)\n",
    "        fcData.to_csv(path_or_buf=fc_data_file, index=True)\n",
    "    else:\n",
    "        fcData = pd.read_csv(fc_data_file, index_col=0)\n",
    "    fcData['func_perc_quart'] = pd.qcut(fcData['func_perc_fd'], q=4, labels=False)\n",
    "    return fcData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datas = read_fc_data_file( './abide_fc_data_fisher_z.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 2]), array([504, 530]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thing=datas.DX_GROUP.as_matrix()\n",
    "np.unique(thing, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savetxt('blah_counts.csv',np.unique(thing, return_counts=True), delimiter=',', newline=os.linesep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ppc_fc_data(fcData, age_range, motion_threshold, \n",
    "                labels_col = 'DX_GROUP', strata_cols = ['DX_GROUP', 'func_perc_quart', 'SEX'], \n",
    "                agecol='AGE_YRS', motioncol='func_perc_fd'):\n",
    "    ''' Takes an fc file with functional connectivity columns as well as demographics and returns\n",
    "    strata, labels, and features with imputed values.\n",
    "    Args:\n",
    "        fcData (pandas.DataFrame): The fc data file\n",
    "        age_range (tuple): lower and upper age range for sample\n",
    "        motion_threshold (int or float): sample will contain rows with func_perc_fd <= motion_threshold\n",
    "        strata_cols (list of str): columns used to stratify\n",
    "    '''\n",
    "    from sklearn.preprocessing import Imputer\n",
    "    fcData_threshed = fcData.query(agecol + \" >= \" + str(age_range[0]) + \" & \" + agecol + \"<= \" + str(age_range[1]) + \" & \" + motioncol + \" <= \" + str(motion_threshold))\n",
    "    strata = fcData_threshed.groupby(strata_cols).grouper.group_info[0]\n",
    "    labels = fcData_threshed[labels_col].as_matrix()\n",
    "    features = fcData_threshed.loc[:,'#2001_#2002':'#9160_#9170']\n",
    "    features_imputed = Imputer(missing_values='NaN', strategy='mean', axis=0).fit_transform(features)\n",
    "    return strata, labels, features_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_col='AGE_YRS'\n",
    "oos_iter = 10\n",
    "sss_n_iter=10\n",
    "skf_n_folds=3\n",
    "age_range=(6,18)\n",
    "motion_threshold=5\n",
    "sample_size=30\n",
    "classifier = 'svc'\n",
    "cvmethod = 'sss'\n",
    "modelDir = './cv_models/test'\n",
    "outputDir = './cv_output/test'\n",
    "fname_prefix = \"{}_{}_mt{}_n{}\".format(cvmethod, classifier, motion_threshold, sample_size)\n",
    "fc_data_file = './abide_fc_data_fisher_z.csv'\n",
    "fcData = read_fc_data_file(fc_data_file)\n",
    "strata, labels, features = ppc_fc_data(fcData, age_range, motion_threshold, labels_col=labels_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv=True\n",
    "sparse=False\n",
    "classifier='svr' #support vector regression\n",
    "data=features\n",
    "penalty='l1'\n",
    "n_iter=sss_n_iter\n",
    "n_jobs=1\n",
    "saveData=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if sparse:\n",
    "    if classifier == 'svr':\n",
    "        print \"Support vector regression does not support sparse, l1 penalties. `sparse` option ignored.\"\n",
    "    penalty = 'l1'\n",
    "else:\n",
    "    penalty = 'l2'\n",
    "\n",
    "if classifier == 'svc':\n",
    "    from sklearn.svm import LinearSVC\n",
    "    algorithm = LinearSVC(penalty = penalty)\n",
    "    if penalty == 'l1':\n",
    "        algorithm.set_params(dual=False)\n",
    "elif classifier == 'svr':\n",
    "    from sklearn.svm import LinearSVR\n",
    "    algorithm = LinearSVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'svr'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13.,  16.,  14.,  14.,  11.,  12.,  13.,  17.,  12.,  16.,  15.,\n",
       "        15.,  18.,  16.,  11.,  13.,  13.,  10.,  10.,   8.,  11.,  12.,\n",
       "        12.,   9.,   9.,  15.,  11.,  11.,   8.,  10.,   9.,  10.,  14.,\n",
       "        17.,  16.,  15.,  16.,  13.,  12.,  14.,  12.,  12.,  14.,  15.,\n",
       "        13.,  13.,  16.,  14.,  14.,  16.,  16.,  16.,  13.,  14.,  16.,\n",
       "        15.,  12.,  15.,  17.,  15.,  17.,  13.,  13.,  15.,  18.,  14.,\n",
       "        14.,  17.,  14.,  14.,  14.,  16.,  16.,  15.,  15.,  12.,  14.,\n",
       "        14.,  12.,  12.,  11.,  12.,  16.,   9.,   9.,  16.,  13.,   9.,\n",
       "        15.,  18.,  18.,  13.,  15.,  17.,  16.,  17.,  11.,  17.,  14.,\n",
       "        13.,  18.,  16.,  18.,  18.,  17.,  18.,  15.,  18.,  12.,  16.,\n",
       "        13.,  17.,   9.,   9.,  13.,  18.,  11.,  15.,  14.,  10.,   9.,\n",
       "        11.,  11.,  14.,  17.,  17.,  14.,  14.,  14.,  17.,  13.,  15.,\n",
       "        16.,  16.,  14.,  13.,  13.,  17.,  13.,  15.,  17.,  16.,  13.,\n",
       "        15.,  15.,  18.,  13.,  18.,  17.,  17.,  18.,  18.,  11.,  15.,\n",
       "        12.,   8.,  14.,  10.,  13.,   9.,  13.,   9.,  13.,  16.,  16.,\n",
       "        15.,  10.,   8.,  14.,  16.,  16.,  12.,  13.,   7.,   9.,  14.,\n",
       "        18.,  13.,  13.,  15.,  16.,  15.,  16.,  12.,  14.,  14.,  13.,\n",
       "        12.,  15.,  12.,  14.,  14.,  13.,  13.,  14.,  14.,  14.,  12.,\n",
       "        12.,  10.,  10.,   8.,  10.,   8.,  10.,  11.,   8.,   8.,   9.,\n",
       "        11.,   9.,   8.,  10.,  14.,  14.,  10.,  15.,   9.,   8.,  17.,\n",
       "        11.,  14.,   7.,   9.,   9.,  13.,   8.,  14.,   9.,  13.,  10.,\n",
       "        15.,  16.,  15.,  14.,   8.,  11.,  11.,   8.,  11.,  18.,   8.,\n",
       "         8.,   8.,   8.,   8.,   8.,  10.,  11.,  11.,  12.,  12.,  13.,\n",
       "        13.,  14.,  14.,  14.,  14.,  15.,  17.,   7.,  10.,  18.,   8.,\n",
       "        10.,  11.,  12.,  12.,  14.,  16.,   6.,   8.,   8.,   9.,  10.,\n",
       "        10.,  11.,  11.,  11.,  13.,  13.,  13.,  13.,  14.,  14.,  15.,\n",
       "        15.,  15.,  15.,  16.,  16.,  10.,  12.,  16.,  16.,  17.,  12.,\n",
       "        16.,  13.,  13.,  12.,  15.,  14.,   8.,   8.,  12.,   9.,  11.,\n",
       "        11.,   7.,   9.,  10.,   9.,   8.,   8.,   8.,  12.,  12.,  12.,\n",
       "        17.,  15.,  16.,  11.,  12.,  14.,  17.,  10.,  17.,  14.,  10.,\n",
       "        13.,   8.,  10.,  11.,  14.,  14.,  15.,  13.,  13.,  13.,  15.,\n",
       "        11.,  17.,  12.,  13.,  12.,  13.,  12.,  13.,   9.,  11.,  16.,\n",
       "        13.,  13.,  12.,   9.,  11.,  13.,  13.,  10.,  11.,  17.,  17.,\n",
       "        18.])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(labels=[2 2 ..., 4 4], n_iter=10, test_size=0.3, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=LinearSVR(C=1.0, dual=True, epsilon=0.0, fit_intercept=True,\n",
       "     intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "     random_state=None, tol=0.0001, verbose=0),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [0.001, 0.005, 0.01, 0.1, 1, 10]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if cv:\n",
    "    from sklearn.grid_search import GridSearchCV\n",
    "    paramsToSearch = []        \n",
    "    paramsToSearch.append({'C': [.001,.005,.01,.1,1,10]})\n",
    "    if cvmethod == 'sss':\n",
    "        from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "        cvalgorithm = StratifiedShuffleSplit(strata, n_iter = n_iter, test_size = .3)\n",
    "    if cvmethod == 'skf':\n",
    "        from sklearn.cross_validation import StratifiedKFold\n",
    "        cvalgorithm = StratifiedKFold(strata, n_folds = n_folds, shuffle = True)\n",
    "    clf=[]\n",
    "    clf = GridSearchCV(algorithm, \n",
    "                       paramsToSearch, \n",
    "                       cv=cvalgorithm,\n",
    "                       n_jobs=n_jobs)\n",
    "else:\n",
    "    #Defaults and train model\n",
    "    clf = algorithm\n",
    "clf.fit(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE: 0.000493\n",
      "Training R^2: 1.000000\n"
     ]
    }
   ],
   "source": [
    "#Get training accuracy\n",
    "trainingPredictions = clf.predict(data)\n",
    "if classifier=='svc':\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    accuracy = accuracy_score(trainingPredictions, labels)\n",
    "    print \"Training accuracy: %f\" % accuracy\n",
    "elif classifier=='svr':\n",
    "    from sklearn.metrics import mean_squared_error, r2_score\n",
    "    MSE = mean_squared_error(trainingPredictions, labels)\n",
    "    RMSE = abs(MSE)**.5\n",
    "    R2 = r2_score(trainingPredictions, labels)\n",
    "    print \"Training RMSE: %f\" % RMSE\n",
    "    print \"Training R^2: %f\" % R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if cv:\n",
    "    #Extract tuned model weights\n",
    "    if classifier=='svc':\n",
    "        modelWeights = clf.best_estimator_.coef_[0]\n",
    "        modelIntercept = clf.best_estimator_.intercept_\n",
    "    elif classifier=='svr':\n",
    "        modelWeights = clf.best_estimator_.coef_\n",
    "        modelIntercept = clf.best_estimator_.intercept_\n",
    "else:\n",
    "    #Extract deafult model weights\n",
    "    if classifier=='svc':\n",
    "        modelWeights = clf.best_estimator_.coef_[0]\n",
    "        modelIntercept = clf.best_estimator_.intercept_\n",
    "    elif classifier=='svr':\n",
    "        modelWeights = clf.coef_\n",
    "        modelIntercept = clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.05847647  0.0972536  -0.00559011 ..., -0.00511297 -0.05498672\n",
      "  0.03412322]\n",
      "[ 0.25228141]\n"
     ]
    }
   ],
   "source": [
    "print modelWeights\n",
    "print modelIntercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if saveData:\n",
    "    if (not modelDir) | (not fname_prefix):\n",
    "        raise TypeError('Model dir or file name not specified')\n",
    "    print \"Saving model weights, training accuracy, and model\"\n",
    "    from sklearn.externals import joblib\n",
    "    #Write intercept + model weights to csv \n",
    "    if not os.path.exists(modelDir):\n",
    "        print (\"{} does not exist; creating ...\".format(modelDir))\n",
    "        os.makedirs(modelDir)\n",
    "    fileName = os.path.join(modelDir, fname_prefix)\n",
    "    print (\"Writing data to {}*\".format(fileName))\n",
    "    np.savetxt(fileName + '_Weights.csv',np.concatenate([modelIntercept,modelWeights]), delimiter=',', newline=os.linesep)\n",
    "    np.savetxt(fileName + '_TrainAcc.csv',np.array([accuracy]), delimiter=',',newline=os.linesep)\n",
    "    joblib.dump(clf, fileName + '_Model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainModel(data, labels, strata, modelDir = None, fname_prefix = None, classifier = 'svc',  cv = True, cvmethod = 'sss', n_iter = 10, k = 10, sparse = True, saveData = True, n_jobs=1):\n",
    "    '''Applies classifier to predict labels from data, stratified by strata, and returns the resulting model.\n",
    "    Optionally saves the model and coefficients.\n",
    "    Args:\n",
    "        data (numpy.ndarray): features to use in prediction\n",
    "        labels (numpy.ndarray): labels to predict\n",
    "        strata (numpy.ndarray): labels to use for stratification\n",
    "        classifier (str): classifier to use. currently only svc is implemented\n",
    "        modelDir (str): where to save model and csv files\n",
    "        fname_prefix (str): what to attach to the beginning of the filename\n",
    "        cv (bool): implement cross validation? currently this must be true\n",
    "        cvmethod (str): cross validation method, 'sss' for StratifiedShuffleSplit or 'skf' for StratifiedKFold.\n",
    "        n_iter (int): number of times to iterate the StratifiedShuffleSplit; default true\n",
    "        k (int): if classifier is StratifiedKFold, number of folds; default true\n",
    "        sparse (bool): whether to use l1 (sparse) regularization or l2; default True\n",
    "        saveData (bool): save the results to model directory? default True\n",
    "        n_jobs (int): number of jobs to pass to cv\n",
    "    '''\n",
    "    if sparse:\n",
    "        penalty = 'l1'\n",
    "    else:\n",
    "        penalty = 'l2'\n",
    "    if classifier == 'svc':\n",
    "        from sklearn.svm import LinearSVC\n",
    "        algorithm = LinearSVC(penalty = penalty)\n",
    "        if penalty == 'l1':\n",
    "            algorithm.set_params(dual=False)\n",
    "    if cv:\n",
    "        from sklearn.grid_search import GridSearchCV\n",
    "        paramsToSearch = []        \n",
    "        paramsToSearch.append({'C': [.001,.005,.01,.1,1,10]})\n",
    "        if cvmethod == 'sss':\n",
    "            from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "            cvalgorithm = StratifiedShuffleSplit(strata, n_iter = n_iter, test_size = .3)\n",
    "        if cvmethod == 'skf':\n",
    "            from sklearn.cross_validation import StratifiedKFold\n",
    "            cvalgorithm = StratifiedKFold(strata, n_folds = n_folds, shuffle = True)\n",
    "        clf=[]\n",
    "        clf = GridSearchCV(algorithm, \n",
    "                           paramsToSearch, \n",
    "                           cv=cvalgorithm,\n",
    "                           n_jobs=n_jobs)\n",
    "    else:\n",
    "        #Defaults and train model\n",
    "        clf = algorithm\n",
    "    clf.fit(data, labels)\n",
    "    \n",
    "    #Get training accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    trainingPredictions = clf.predict(data)\n",
    "    accuracy = accuracy_score(trainingPredictions, labels)\n",
    "    print \"Training accuracy: %f\" % accuracy\n",
    "\n",
    "    if cv:\n",
    "        #Extract tuned model weights\n",
    "        modelWeights = clf.best_estimator_.coef_[0]\n",
    "        modelIntercept = clf.best_estimator_.intercept_\n",
    "    else:\n",
    "        #Extract deafult model weights\n",
    "        modelWeights = clf.coef_[0]\n",
    "        modelIntercept = clf.intercept_\n",
    "    \n",
    "    if saveData:\n",
    "        if (not modelDir) | (not fname_prefix):\n",
    "            raise TypeError('Model dir or file name not specified')\n",
    "        print \"Saving model weights, training accuracy, and model\"\n",
    "        from sklearn.externals import joblib\n",
    "        #Write intercept + model weights to csv \n",
    "        if not os.path.exists(modelDir):\n",
    "            print (\"{} does not exist; creating ...\".format(modelDir))\n",
    "            os.makedirs(modelDir)\n",
    "        fileName = os.path.join(modelDir, fname_prefix)\n",
    "        print (\"Writing data to {}*\".format(fileName))\n",
    "        np.savetxt(fileName + '_Weights.csv',np.concatenate([modelIntercept,modelWeights]), delimiter=',', newline=os.linesep)\n",
    "        np.savetxt(fileName + '_TrainAcc.csv',np.array([accuracy]), delimiter=',',newline=os.linesep)\n",
    "        joblib.dump(clf, fileName + '_Model.pkl')\n",
    "        \n",
    "    return (clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def testModel(data, labels, clf = None, modelDir = None, fname_prefix = None, outputDir = None, saveData=True):\n",
    "    \n",
    "    ''' Test a linear classifier by loading a fitted model and returning predictions on given data.\n",
    "    Args:\n",
    "        data (ndarray): A data matrix organized as nsamples x nfeatures \n",
    "        labels (ndarray): A 1d labels array same length as nsamples  \n",
    "        clf (sklearn fit object): If not specified, fucntion will try to load using modelDir and fname_prefix\n",
    "        modelDir (str): directory from which to load pickled model files\n",
    "        fname_prefix (str): filename prefix used for model files\n",
    "        outDir (str): directory to write csv file with testing accuracy and predictions\n",
    "        saveData (bool; optional): whether to actually save csv or just return model object; \n",
    "            default True\n",
    "    '''\n",
    "\n",
    "    from sklearn.externals import joblib\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    if not clf:\n",
    "        if (not modelDir) | (not fname_prefix):\n",
    "            raise TypeError('No clf provided and Model dir or file name not specified')\n",
    "        modelPath = os.path.join(modelDir, fname_prefix)\n",
    "        #If model doesn't exist use csv with coefs - TODO\n",
    "        clf = joblib.load(modelPath + '_Model.pkl')\n",
    "    predictions = clf.predict(data)\n",
    "\n",
    "    #Compute accuracy on test data\n",
    "    accuracy = accuracy_score(predictions,labels)\n",
    "    print \"Testing accuracy: %f\" % accuracy\n",
    "\n",
    "    if saveData:\n",
    "        from sklearn.externals import joblib\n",
    "        if (not outputDir) | (not fname_prefix):\n",
    "            raise TypeError('Output dir or file name not specified')\n",
    "        if not os.path.exists(outputDir):\n",
    "            print (\"{} does not exist; creating ...\".format(outputDir))\n",
    "            os.makedirs(outputDir)\n",
    "        outPath = os.path.join(outputDir, fname_prefix)\n",
    "        print \"Saving test accuracy and predictions to {}*\".format(outPath)\n",
    "        #Save accuracy\n",
    "        np.savetxt(outPath + '_TestAcc.csv', np.array([accuracy]), delimiter=',',newline=os.linesep)\n",
    "        #Save predictions\n",
    "        np.savetxt(outPath + '_Predictions.csv',predictions, delimiter=',',newline=os.linesep)\n",
    "\n",
    "    return accuracy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oos_iter = 10\n",
    "sss_n_iter=10\n",
    "skf_n_folds=3\n",
    "age_range=(6,18)\n",
    "motion_threshold=5\n",
    "sample_size=30\n",
    "classifier = 'svc'\n",
    "cvmethod = 'sss'\n",
    "modelDir = './cv_models/test'\n",
    "outputDir = './cv_output/test'\n",
    "fname_prefix = \"{}_{}_mt{}_n{}\".format(cvmethod, classifier, motion_threshold, sample_size)\n",
    "fc_data_file = './abide_fc_data_fisher_z.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fcData = read_fc_data_file(fc_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "strata, labels, features = ppc_fc_data(fcData, age_range, motion_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(strata, n_iter = oos_iter, test_size = sample_size, train_size = sample_size)\n",
    "\n",
    "print(\"Running {} iterations of {} cv'd {} classification\\n\".format(oos_iter, cvmethod, classifier) + \n",
    "      \"Each N = {}, Motion thresh = {}\".format(sample_size, motion_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, (train_index, test_index) in enumerate(sss):\n",
    "    train_features, train_labels = features[train_index, :], labels[train_index]\n",
    "    test_features, test_labels = features[test_index, :], labels[test_index]\n",
    "    ifname_prefix = fname_prefix + '_i{:03d}'.format(i)\n",
    "    aCLF = trainModel(train_features, train_labels, train_labels, \n",
    "                      modelDir=modelDir, fname_prefix=ifname_prefix, \n",
    "                      classifier = classifier,  \n",
    "                      cv = True, cvmethod = cvmethod, \n",
    "                      n_iter = sss_n_iter, k = skf_n_folds, \n",
    "                      sparse = True, saveData = True, n_jobs=4)\n",
    "    accuracy = testModel(test_features, test_labels, clf = aCLF, \n",
    "                         fname_prefix = ifname_prefix, \n",
    "                         outputDir = outputDir, saveData=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:kidsPy2]",
   "language": "python",
   "name": "conda-env-kidsPy2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
